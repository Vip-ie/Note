# 爬虫基础

---

1. **爬虫的概念**
2. **爬虫的流程**
3. **HTTP协议**
4. **WEBSOCKET协议**

---

## 爬虫基础

### 什么是爬虫？

**爬虫的概念**

* 爬虫更官方店的名字叫数据采集，英文一般称作spider，就是通过程序来全自动的从互联网上采集数据。
* 比如说搜索引擎就是一种爬虫。
* 爬虫需要做的就是模拟正常的网络请求，比如你的网站上点击一个网址，就是一此网络请求。

---

### **爬虫有什么用？**

**爬虫的作用**

* 现如今大数据时代已经到来，网络爬虫技术成为这个时代不可或缺的一部分，企业需要数据来分析用户行为，来分析自己产品的不足之处，来分析竞争对手的信息等等，但是这些的首要条件就是数据的采集。
* 这其中使用爬虫较为有名的有今日头条等公司。

---

**爬虫的本质**

* 爬虫的本质就是自动化的去模拟正常人类发起的网络请求，然后获取网络请求所返回的数据。
* 跟我们人手动点击一个连接，访问一个网页获取数据，并没有什么本质的区别。

---

**爬虫的难点**

爬虫的难点主要为两个方向：

1. 数据的获取

> 一般来说我们想要抓取的网站是不希望我们去抓取他们的数据的，那么这些网站就会做一些反爬虫的措施，来让我们无法去他的网站上抓取数据。所以我们也要做相应的措施去绕过这些反爬虫措施。

   2. 抓取数据的速度

> 我们抓取的目标的数据量，有时是非常庞大的，甚至几千万上亿的数据量，而有些甚至会要求实时的更新，所以抓取的速度也非常重要，我们一般会使用并发和分布式来解决速度的问题。

---



